{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3aeb571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import flappy_bird_gymnasium\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plot\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271c1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "STACK_SIZE = 4\n",
    "BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99\n",
    "LR = 1e-4\n",
    "TARGET_UPDATE = 1000\n",
    "EPISODES= 5000\n",
    "EPS_START = 1.0\n",
    "EPS_END = 0.01\n",
    "EPS_DECAY_RATE = 0.998\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(frame):\n",
    "    if frame is None or len(frame.shape) != 3 or frame.shape[2] != 3:\n",
    "        frame = np.zeros((288, 512, 3), dtype=np.uint8)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.resize(gray, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "    return gray.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bfa38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_experiment(base_dir=\"checkpoints\"):\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    existing = glob.glob(os.path.join(base_dir, \"exp_*\"))\n",
    "    ids = [int(e.split(\"_\")[-1]) for e in existing if \"_\" in e]\n",
    "    next_id = max(ids) + 1 if ids else 1\n",
    "    path = os.path.join(base_dir, f\"exp_{next_id:03d}\")\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    print(f\"Initialized: {path}\")\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e6d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized: checkpoints\\exp_015\n"
     ]
    }
   ],
   "source": [
    "exp_path=setup_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae01e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlappyCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Q-Network for Flappy Bird with 3 convolutional layers\n",
    "    and 2 fully connected layers.\n",
    "    Input: stacked grayscale frames (C=4, H=84, W=84)\n",
    "    Output: Q-values for each action\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_actions: int, input_channels: int = 4):\n",
    "        super().__init__()\n",
    "        # Convolutional feature extractor\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                input_channels, 32, kernel_size=8, stride=4\n",
    "            ),  # 84x84x4 -> 20x20x32\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),  # 20x20x32 -> 9x9x64\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),  # 9x9x64 -> 7x7x64\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),  # 7x7x64 = 3136\n",
    "        )\n",
    "\n",
    "        # Dynamically compute the flattened size after convs\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, input_channels, 84, 84)\n",
    "            conv_out_size = self.conv(dummy).size(1)\n",
    "\n",
    "        # Fully connected decision layers\n",
    "        self.state_value_stream = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 512), nn.ReLU(), nn.Linear(512, 1)\n",
    "        )\n",
    "        \n",
    "        self.action_advantage_stream = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 512), nn.ReLU(), nn.Linear(512, num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        state_value = self.state_value_stream(x)\n",
    "        action_advantage = self.action_advantage_stream(x)\n",
    "        return state_value + (action_advantage - action_advantage.mean(dim=1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152c05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    Fixed-size buffer to store experience tuples for DQN.\n",
    "    Stores: (state, action, reward, next_state, done)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity: int):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state: torch.Tensor, action: int, reward: float,\n",
    "             next_state: torch.Tensor, done: bool):\n",
    "        \"\"\"\n",
    "        Add a transition to the buffer.\n",
    "        All states are expected as torch.FloatTensor.\n",
    "        \"\"\"\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size: int):\n",
    "        \"\"\"\n",
    "        Sample a random batch from memory.\n",
    "        Returns tensors suitable for training.\n",
    "        \"\"\"\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "        states = torch.stack(states) \n",
    "        next_states = torch.stack(next_states)\n",
    "        actions = torch.tensor(actions, dtype=torch.long)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "        dones = torch.tensor(dones, dtype=torch.float32)\n",
    "\n",
    "        return states, actions, rewards, next_states, dones\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1078ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameStack:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        self.frames = deque(maxlen=k)\n",
    "\n",
    "    def reset(self, frame):\n",
    "        for _ in range(self.k):\n",
    "            self.frames.append(frame)\n",
    "        return torch.from_numpy(np.stack(self.frames, axis=0))\n",
    "\n",
    "    def step(self, frame):\n",
    "        self.frames.append(frame)\n",
    "        return torch.from_numpy(np.stack(self.frames, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a3c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FlappyBird-v0\", render_mode=\"rgb_array\")\n",
    "num_actions = env.action_space.n\n",
    "stacker = FrameStack(STACK_SIZE)\n",
    "\n",
    "policy_net = FlappyCNN(num_actions).to(DEVICE)\n",
    "target_net = FlappyCNN(num_actions).to(DEVICE)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LR)\n",
    "replay_buffer = ReplayBuffer(BUFFER_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f06109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "c:\\Users\\nickh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 10 | Average Score: 0.0 | Best: 0 | Epsilon: 0.980\n",
      "Episode: 20 | Average Score: 0.0 | Best: 0 | Epsilon: 0.961\n",
      "Episode: 30 | Average Score: 0.0 | Best: 0 | Epsilon: 0.942\n",
      "Episode: 40 | Average Score: 0.0 | Best: 0 | Epsilon: 0.923\n",
      "Episode: 50 | Average Score: 0.0 | Best: 0 | Epsilon: 0.905\n",
      "Episode: 60 | Average Score: 0.0 | Best: 0 | Epsilon: 0.887\n",
      "Episode: 70 | Average Score: 0.0 | Best: 0 | Epsilon: 0.869\n",
      "Episode: 80 | Average Score: 0.0 | Best: 0 | Epsilon: 0.852\n",
      "Episode: 90 | Average Score: 0.0 | Best: 0 | Epsilon: 0.835\n",
      "Episode: 100 | Average Score: 0.0 | Best: 0 | Epsilon: 0.819\n",
      "Episode: 110 | Average Score: 0.0 | Best: 0 | Epsilon: 0.802\n",
      "Episode: 120 | Average Score: 0.0 | Best: 0 | Epsilon: 0.786\n",
      "Episode: 130 | Average Score: 0.0 | Best: 0 | Epsilon: 0.771\n",
      "Episode: 140 | Average Score: 0.0 | Best: 0 | Epsilon: 0.756\n",
      "Episode: 150 | Average Score: 0.0 | Best: 0 | Epsilon: 0.741\n",
      "Episode: 160 | Average Score: 0.0 | Best: 0 | Epsilon: 0.726\n",
      "Episode: 170 | Average Score: 0.0 | Best: 0 | Epsilon: 0.712\n",
      "Episode: 180 | Average Score: 0.0 | Best: 0 | Epsilon: 0.697\n",
      "Episode: 190 | Average Score: 0.0 | Best: 0 | Epsilon: 0.684\n",
      "Episode: 200 | Average Score: 0.0 | Best: 0 | Epsilon: 0.670\n",
      "Episode: 210 | Average Score: 0.0 | Best: 0 | Epsilon: 0.657\n",
      "Episode: 220 | Average Score: 0.0 | Best: 0 | Epsilon: 0.644\n",
      "Episode: 230 | Average Score: 0.0 | Best: 0 | Epsilon: 0.631\n",
      "Episode: 240 | Average Score: 0.0 | Best: 0 | Epsilon: 0.618\n",
      "Episode: 250 | Average Score: 0.0 | Best: 0 | Epsilon: 0.606\n",
      "Episode: 260 | Average Score: 0.0 | Best: 0 | Epsilon: 0.594\n",
      "Episode: 270 | Average Score: 0.0 | Best: 0 | Epsilon: 0.582\n",
      "Episode: 280 | Average Score: 0.0 | Best: 0 | Epsilon: 0.571\n",
      "Episode: 290 | Average Score: 0.0 | Best: 0 | Epsilon: 0.560\n",
      "Episode: 300 | Average Score: 0.0 | Best: 0 | Epsilon: 0.548\n",
      "Episode: 310 | Average Score: 0.0 | Best: 0 | Epsilon: 0.538\n",
      "Episode: 320 | Average Score: 0.0 | Best: 0 | Epsilon: 0.527\n",
      "Episode: 330 | Average Score: 0.0 | Best: 0 | Epsilon: 0.517\n",
      "Episode: 340 | Average Score: 0.0 | Best: 0 | Epsilon: 0.506\n",
      "Episode: 350 | Average Score: 0.0 | Best: 0 | Epsilon: 0.496\n",
      "Episode: 360 | Average Score: 0.0 | Best: 0 | Epsilon: 0.486\n",
      "Episode: 370 | Average Score: 0.0 | Best: 0 | Epsilon: 0.477\n",
      "Episode: 380 | Average Score: 0.0 | Best: 0 | Epsilon: 0.467\n",
      "Episode: 390 | Average Score: 0.0 | Best: 0 | Epsilon: 0.458\n",
      "Episode: 400 | Average Score: 0.0 | Best: 0 | Epsilon: 0.449\n",
      "Episode: 410 | Average Score: 0.0 | Best: 0 | Epsilon: 0.440\n",
      "Episode: 420 | Average Score: 0.0 | Best: 0 | Epsilon: 0.431\n",
      "Episode: 430 | Average Score: 0.0 | Best: 0 | Epsilon: 0.423\n",
      "Episode: 440 | Average Score: 0.0 | Best: 0 | Epsilon: 0.414\n",
      "Episode: 450 | Average Score: 0.0 | Best: 0 | Epsilon: 0.406\n",
      "Episode: 460 | Average Score: 0.0 | Best: 0 | Epsilon: 0.398\n",
      "Episode: 470 | Average Score: 0.0 | Best: 0 | Epsilon: 0.390\n",
      "Episode: 480 | Average Score: 0.0 | Best: 0 | Epsilon: 0.383\n",
      "Episode: 490 | Average Score: 0.0 | Best: 0 | Epsilon: 0.375\n",
      "Episode: 500 | Average Score: 0.0 | Best: 0 | Epsilon: 0.368\n",
      "Episode: 510 | Average Score: 0.0 | Best: 0 | Epsilon: 0.360\n",
      "Episode: 520 | Average Score: 0.0 | Best: 0 | Epsilon: 0.353\n",
      "Episode: 530 | Average Score: 0.0 | Best: 0 | Epsilon: 0.346\n",
      "Episode: 540 | Average Score: 0.0 | Best: 0 | Epsilon: 0.339\n",
      "Episode: 550 | Average Score: 0.0 | Best: 0 | Epsilon: 0.333\n",
      "Episode: 560 | Average Score: 0.0 | Best: 0 | Epsilon: 0.326\n",
      "Episode: 570 | Average Score: 0.0 | Best: 0 | Epsilon: 0.319\n",
      "Episode: 580 | Average Score: 0.0 | Best: 0 | Epsilon: 0.313\n",
      "Episode: 590 | Average Score: 0.0 | Best: 0 | Epsilon: 0.307\n",
      "Episode: 600 | Average Score: 0.0 | Best: 0 | Epsilon: 0.301\n",
      "Episode: 610 | Average Score: 0.0 | Best: 0 | Epsilon: 0.295\n",
      "Episode: 620 | Average Score: 0.0 | Best: 0 | Epsilon: 0.289\n",
      "Episode: 630 | Average Score: 0.0 | Best: 0 | Epsilon: 0.283\n",
      "Episode: 640 | Average Score: 0.0 | Best: 0 | Epsilon: 0.278\n",
      "Episode: 650 | Average Score: 0.0 | Best: 0 | Epsilon: 0.272\n",
      "Episode: 660 | Average Score: 0.0 | Best: 0 | Epsilon: 0.267\n",
      "Episode: 670 | Average Score: 0.0 | Best: 0 | Epsilon: 0.261\n",
      "Episode: 680 | Average Score: 0.0 | Best: 0 | Epsilon: 0.256\n",
      "Episode: 690 | Average Score: 0.0 | Best: 0 | Epsilon: 0.251\n",
      "Episode: 700 | Average Score: 0.0 | Best: 0 | Epsilon: 0.246\n",
      "Episode: 710 | Average Score: 0.0 | Best: 0 | Epsilon: 0.241\n",
      "Episode: 720 | Average Score: 0.0 | Best: 0 | Epsilon: 0.237\n",
      "Episode: 730 | Average Score: 0.0 | Best: 0 | Epsilon: 0.232\n",
      "Episode: 740 | Average Score: 0.0 | Best: 0 | Epsilon: 0.227\n",
      "Episode: 750 | Average Score: 0.0 | Best: 0 | Epsilon: 0.223\n",
      "Episode: 760 | Average Score: 0.0 | Best: 0 | Epsilon: 0.218\n",
      "Episode: 770 | Average Score: 0.0 | Best: 0 | Epsilon: 0.214\n",
      "Episode: 780 | Average Score: 0.0 | Best: 0 | Epsilon: 0.210\n",
      "Episode: 790 | Average Score: 0.0 | Best: 0 | Epsilon: 0.206\n",
      "Episode: 800 | Average Score: 0.0 | Best: 0 | Epsilon: 0.202\n",
      "Episode: 810 | Average Score: 0.0 | Best: 0 | Epsilon: 0.198\n",
      "Episode: 820 | Average Score: 0.0 | Best: 0 | Epsilon: 0.194\n",
      "Episode: 830 | Average Score: 0.0 | Best: 0 | Epsilon: 0.190\n",
      "Episode: 840 | Average Score: 0.0 | Best: 0 | Epsilon: 0.186\n",
      "Episode: 850 | Average Score: 0.0 | Best: 0 | Epsilon: 0.182\n",
      "Episode: 860 | Average Score: 0.0 | Best: 0 | Epsilon: 0.179\n",
      "Episode: 870 | Average Score: 0.0 | Best: 0 | Epsilon: 0.175\n",
      "Episode: 880 | Average Score: 0.0 | Best: 0 | Epsilon: 0.172\n",
      "Episode: 890 | Average Score: 0.0 | Best: 0 | Epsilon: 0.168\n",
      "Episode: 900 | Average Score: 0.0 | Best: 0 | Epsilon: 0.165\n",
      "Episode: 910 | Average Score: 0.0 | Best: 0 | Epsilon: 0.162\n",
      "Episode: 920 | Average Score: 0.0 | Best: 0 | Epsilon: 0.159\n",
      "Episode: 930 | Average Score: 0.0 | Best: 0 | Epsilon: 0.155\n",
      "Episode: 940 | Average Score: 0.0 | Best: 0 | Epsilon: 0.152\n",
      "Episode: 950 | Average Score: 0.0 | Best: 0 | Epsilon: 0.149\n",
      "Episode: 960 | Average Score: 0.0 | Best: 0 | Epsilon: 0.146\n",
      "Episode: 970 | Average Score: 0.0 | Best: 0 | Epsilon: 0.143\n",
      "Episode: 980 | Average Score: 0.1 | Best: 1 | Epsilon: 0.141\n",
      "Episode: 990 | Average Score: 0.0 | Best: 1 | Epsilon: 0.138\n",
      "Episode: 1000 | Average Score: 0.0 | Best: 1 | Epsilon: 0.135\n",
      "Episode: 1010 | Average Score: 0.0 | Best: 1 | Epsilon: 0.132\n",
      "Episode: 1020 | Average Score: 0.0 | Best: 1 | Epsilon: 0.130\n",
      "Episode: 1030 | Average Score: 0.0 | Best: 1 | Epsilon: 0.127\n",
      "Episode: 1040 | Average Score: 0.0 | Best: 1 | Epsilon: 0.125\n",
      "Episode: 1050 | Average Score: 0.0 | Best: 1 | Epsilon: 0.122\n",
      "Episode: 1060 | Average Score: 0.0 | Best: 1 | Epsilon: 0.120\n",
      "Episode: 1070 | Average Score: 0.0 | Best: 1 | Epsilon: 0.117\n",
      "Episode: 1080 | Average Score: 0.0 | Best: 1 | Epsilon: 0.115\n",
      "Episode: 1090 | Average Score: 0.0 | Best: 1 | Epsilon: 0.113\n",
      "Episode: 1100 | Average Score: 0.0 | Best: 1 | Epsilon: 0.111\n",
      "Episode: 1110 | Average Score: 0.0 | Best: 1 | Epsilon: 0.108\n",
      "Episode: 1120 | Average Score: 0.0 | Best: 1 | Epsilon: 0.106\n",
      "Episode: 1130 | Average Score: 0.0 | Best: 1 | Epsilon: 0.104\n",
      "Episode: 1140 | Average Score: 0.0 | Best: 1 | Epsilon: 0.102\n",
      "Episode: 1150 | Average Score: 0.0 | Best: 1 | Epsilon: 0.100\n",
      "Episode: 1160 | Average Score: 0.0 | Best: 1 | Epsilon: 0.098\n",
      "Episode: 1170 | Average Score: 0.0 | Best: 1 | Epsilon: 0.096\n",
      "Episode: 1180 | Average Score: 0.0 | Best: 1 | Epsilon: 0.094\n",
      "Episode: 1190 | Average Score: 0.0 | Best: 1 | Epsilon: 0.092\n",
      "Episode: 1200 | Average Score: 0.0 | Best: 1 | Epsilon: 0.091\n",
      "Episode: 1210 | Average Score: 0.0 | Best: 1 | Epsilon: 0.089\n",
      "Episode: 1220 | Average Score: 0.0 | Best: 1 | Epsilon: 0.087\n",
      "Episode: 1230 | Average Score: 0.0 | Best: 1 | Epsilon: 0.085\n",
      "Episode: 1240 | Average Score: 0.0 | Best: 1 | Epsilon: 0.084\n",
      "Episode: 1250 | Average Score: 0.0 | Best: 1 | Epsilon: 0.082\n",
      "Episode: 1260 | Average Score: 0.0 | Best: 1 | Epsilon: 0.080\n",
      "Episode: 1270 | Average Score: 0.0 | Best: 1 | Epsilon: 0.079\n",
      "Episode: 1280 | Average Score: 0.0 | Best: 1 | Epsilon: 0.077\n",
      "Episode: 1290 | Average Score: 0.0 | Best: 1 | Epsilon: 0.076\n",
      "Episode: 1300 | Average Score: 0.0 | Best: 1 | Epsilon: 0.074\n",
      "Episode: 1310 | Average Score: 0.0 | Best: 1 | Epsilon: 0.073\n",
      "Episode: 1320 | Average Score: 0.0 | Best: 1 | Epsilon: 0.071\n",
      "Episode: 1330 | Average Score: 0.0 | Best: 1 | Epsilon: 0.070\n",
      "Episode: 1340 | Average Score: 0.0 | Best: 1 | Epsilon: 0.068\n",
      "Episode: 1350 | Average Score: 0.2 | Best: 1 | Epsilon: 0.067\n",
      "Episode: 1360 | Average Score: 0.0 | Best: 1 | Epsilon: 0.066\n",
      "Episode: 1370 | Average Score: 0.0 | Best: 1 | Epsilon: 0.064\n",
      "Episode: 1380 | Average Score: 0.0 | Best: 1 | Epsilon: 0.063\n",
      "Episode: 1390 | Average Score: 0.0 | Best: 1 | Epsilon: 0.062\n",
      "Episode: 1400 | Average Score: 0.0 | Best: 1 | Epsilon: 0.061\n",
      "Episode: 1410 | Average Score: 0.0 | Best: 1 | Epsilon: 0.059\n",
      "Episode: 1420 | Average Score: 0.2 | Best: 1 | Epsilon: 0.058\n",
      "Episode: 1430 | Average Score: 0.1 | Best: 1 | Epsilon: 0.057\n",
      "Episode: 1440 | Average Score: 0.2 | Best: 1 | Epsilon: 0.056\n",
      "Episode: 1450 | Average Score: 0.1 | Best: 1 | Epsilon: 0.055\n",
      "Episode: 1460 | Average Score: 0.1 | Best: 1 | Epsilon: 0.054\n",
      "Episode: 1470 | Average Score: 0.3 | Best: 1 | Epsilon: 0.053\n",
      "Episode: 1480 | Average Score: 0.0 | Best: 1 | Epsilon: 0.052\n",
      "Episode: 1490 | Average Score: 0.2 | Best: 1 | Epsilon: 0.051\n",
      "Episode: 1500 | Average Score: 0.2 | Best: 1 | Epsilon: 0.050\n",
      "Episode: 1510 | Average Score: 0.4 | Best: 1 | Epsilon: 0.049\n",
      "Episode: 1520 | Average Score: 0.1 | Best: 1 | Epsilon: 0.048\n",
      "Episode: 1530 | Average Score: 0.2 | Best: 1 | Epsilon: 0.047\n",
      "Episode: 1540 | Average Score: 0.3 | Best: 1 | Epsilon: 0.046\n",
      "Episode: 1550 | Average Score: 0.2 | Best: 1 | Epsilon: 0.045\n",
      "Episode: 1560 | Average Score: 0.5 | Best: 2 | Epsilon: 0.044\n",
      "Episode: 1570 | Average Score: 0.2 | Best: 2 | Epsilon: 0.043\n",
      "Episode: 1580 | Average Score: 0.1 | Best: 2 | Epsilon: 0.042\n",
      "Episode: 1590 | Average Score: 0.2 | Best: 2 | Epsilon: 0.041\n",
      "Episode: 1600 | Average Score: 0.1 | Best: 2 | Epsilon: 0.041\n",
      "Episode: 1610 | Average Score: 0.7 | Best: 3 | Epsilon: 0.040\n",
      "Episode: 1620 | Average Score: 0.1 | Best: 3 | Epsilon: 0.039\n",
      "Episode: 1630 | Average Score: 0.4 | Best: 3 | Epsilon: 0.038\n",
      "Episode: 1640 | Average Score: 0.4 | Best: 3 | Epsilon: 0.038\n",
      "Episode: 1650 | Average Score: 0.7 | Best: 5 | Epsilon: 0.037\n",
      "Episode: 1660 | Average Score: 0.1 | Best: 5 | Epsilon: 0.036\n",
      "Episode: 1670 | Average Score: 0.2 | Best: 5 | Epsilon: 0.035\n",
      "Episode: 1680 | Average Score: 0.2 | Best: 5 | Epsilon: 0.035\n",
      "Episode: 1690 | Average Score: 0.0 | Best: 5 | Epsilon: 0.034\n",
      "Episode: 1700 | Average Score: 0.2 | Best: 5 | Epsilon: 0.033\n",
      "Episode: 1710 | Average Score: 0.2 | Best: 5 | Epsilon: 0.033\n",
      "Episode: 1720 | Average Score: 0.5 | Best: 5 | Epsilon: 0.032\n",
      "Episode: 1730 | Average Score: 0.1 | Best: 5 | Epsilon: 0.031\n",
      "Episode: 1740 | Average Score: 0.4 | Best: 5 | Epsilon: 0.031\n",
      "Episode: 1750 | Average Score: 0.5 | Best: 5 | Epsilon: 0.030\n",
      "Episode: 1760 | Average Score: 0.5 | Best: 5 | Epsilon: 0.029\n",
      "Episode: 1770 | Average Score: 0.5 | Best: 5 | Epsilon: 0.029\n",
      "Episode: 1780 | Average Score: 0.5 | Best: 5 | Epsilon: 0.028\n",
      "Episode: 1790 | Average Score: 0.0 | Best: 5 | Epsilon: 0.028\n",
      "Episode: 1800 | Average Score: 0.6 | Best: 5 | Epsilon: 0.027\n",
      "Episode: 1810 | Average Score: 0.6 | Best: 5 | Epsilon: 0.027\n",
      "Episode: 1820 | Average Score: 0.5 | Best: 5 | Epsilon: 0.026\n",
      "Episode: 1830 | Average Score: 0.8 | Best: 5 | Epsilon: 0.026\n",
      "Episode: 1840 | Average Score: 0.3 | Best: 5 | Epsilon: 0.025\n",
      "Episode: 1850 | Average Score: 0.5 | Best: 5 | Epsilon: 0.025\n",
      "Episode: 1860 | Average Score: 0.4 | Best: 5 | Epsilon: 0.024\n",
      "Episode: 1870 | Average Score: 0.8 | Best: 5 | Epsilon: 0.024\n",
      "Episode: 1880 | Average Score: 0.6 | Best: 5 | Epsilon: 0.023\n",
      "Episode: 1890 | Average Score: 0.6 | Best: 5 | Epsilon: 0.023\n",
      "Episode: 1900 | Average Score: 0.6 | Best: 5 | Epsilon: 0.022\n",
      "Episode: 1910 | Average Score: 0.7 | Best: 5 | Epsilon: 0.022\n",
      "Episode: 1920 | Average Score: 1.3 | Best: 5 | Epsilon: 0.021\n",
      "Episode: 1930 | Average Score: 1.1 | Best: 5 | Epsilon: 0.021\n",
      "Episode: 1940 | Average Score: 0.9 | Best: 5 | Epsilon: 0.021\n",
      "Episode: 1950 | Average Score: 0.7 | Best: 5 | Epsilon: 0.020\n",
      "Episode: 1960 | Average Score: 1.0 | Best: 5 | Epsilon: 0.020\n",
      "Episode: 1970 | Average Score: 0.4 | Best: 5 | Epsilon: 0.019\n",
      "Episode: 1980 | Average Score: 1.0 | Best: 5 | Epsilon: 0.019\n",
      "Episode: 1990 | Average Score: 0.8 | Best: 5 | Epsilon: 0.019\n",
      "Episode: 2000 | Average Score: 0.8 | Best: 5 | Epsilon: 0.018\n",
      "Episode: 2010 | Average Score: 0.3 | Best: 5 | Epsilon: 0.018\n",
      "Episode: 2020 | Average Score: 1.1 | Best: 5 | Epsilon: 0.018\n",
      "Episode: 2030 | Average Score: 1.2 | Best: 5 | Epsilon: 0.017\n",
      "Episode: 2040 | Average Score: 0.8 | Best: 5 | Epsilon: 0.017\n",
      "Episode: 2050 | Average Score: 1.2 | Best: 5 | Epsilon: 0.017\n",
      "Episode: 2060 | Average Score: 1.9 | Best: 7 | Epsilon: 0.016\n",
      "Episode: 2070 | Average Score: 1.4 | Best: 7 | Epsilon: 0.016\n",
      "Episode: 2080 | Average Score: 0.9 | Best: 7 | Epsilon: 0.016\n",
      "Episode: 2090 | Average Score: 1.0 | Best: 7 | Epsilon: 0.015\n",
      "Episode: 2100 | Average Score: 0.7 | Best: 7 | Epsilon: 0.015\n",
      "Episode: 2110 | Average Score: 1.2 | Best: 7 | Epsilon: 0.015\n",
      "Episode: 2120 | Average Score: 0.9 | Best: 7 | Epsilon: 0.014\n",
      "Episode: 2130 | Average Score: 1.7 | Best: 8 | Epsilon: 0.014\n",
      "Episode: 2140 | Average Score: 0.4 | Best: 8 | Epsilon: 0.014\n",
      "Episode: 2150 | Average Score: 0.7 | Best: 8 | Epsilon: 0.014\n",
      "Episode: 2160 | Average Score: 1.5 | Best: 8 | Epsilon: 0.013\n",
      "Episode: 2170 | Average Score: 1.2 | Best: 8 | Epsilon: 0.013\n",
      "Episode: 2180 | Average Score: 1.8 | Best: 8 | Epsilon: 0.013\n",
      "Episode: 2190 | Average Score: 2.3 | Best: 10 | Epsilon: 0.012\n",
      "Episode: 2200 | Average Score: 2.3 | Best: 10 | Epsilon: 0.012\n",
      "Episode: 2210 | Average Score: 4.5 | Best: 12 | Epsilon: 0.012\n",
      "Episode: 2220 | Average Score: 3.5 | Best: 12 | Epsilon: 0.012\n",
      "Episode: 2230 | Average Score: 1.8 | Best: 12 | Epsilon: 0.012\n",
      "Episode: 2240 | Average Score: 2.6 | Best: 12 | Epsilon: 0.011\n",
      "Episode: 2250 | Average Score: 1.8 | Best: 12 | Epsilon: 0.011\n",
      "Episode: 2260 | Average Score: 1.3 | Best: 12 | Epsilon: 0.011\n",
      "Episode: 2270 | Average Score: 3.5 | Best: 12 | Epsilon: 0.011\n",
      "Episode: 2280 | Average Score: 2.6 | Best: 12 | Epsilon: 0.010\n",
      "Episode: 2290 | Average Score: 3.0 | Best: 12 | Epsilon: 0.010\n",
      "Episode: 2300 | Average Score: 3.1 | Best: 12 | Epsilon: 0.010\n",
      "Episode: 2310 | Average Score: 1.8 | Best: 12 | Epsilon: 0.010\n",
      "Episode: 2320 | Average Score: 2.2 | Best: 12 | Epsilon: 0.010\n",
      "Episode: 2330 | Average Score: 3.5 | Best: 12 | Epsilon: 0.010\n",
      "Episode: 2340 | Average Score: 4.8 | Best: 12 | Epsilon: 0.010\n",
      "Episode: 2350 | Average Score: 3.7 | Best: 12 | Epsilon: 0.010\n",
      "Episode: 2360 | Average Score: 4.7 | Best: 12 | Epsilon: 0.010\n",
      "Episode: 2370 | Average Score: 4.0 | Best: 14 | Epsilon: 0.010\n",
      "Episode: 2380 | Average Score: 5.1 | Best: 17 | Epsilon: 0.010\n",
      "Episode: 2390 | Average Score: 5.4 | Best: 19 | Epsilon: 0.010\n",
      "Episode: 2400 | Average Score: 4.6 | Best: 19 | Epsilon: 0.010\n",
      "Episode: 2410 | Average Score: 9.5 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2420 | Average Score: 5.9 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2430 | Average Score: 3.3 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2440 | Average Score: 6.0 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2450 | Average Score: 10.3 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2460 | Average Score: 5.0 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2470 | Average Score: 7.4 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2480 | Average Score: 7.2 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2490 | Average Score: 3.3 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2500 | Average Score: 6.3 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2510 | Average Score: 8.2 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2520 | Average Score: 7.4 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2530 | Average Score: 6.2 | Best: 30 | Epsilon: 0.010\n",
      "Episode: 2540 | Average Score: 9.1 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2550 | Average Score: 8.1 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2560 | Average Score: 6.2 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2570 | Average Score: 6.3 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2580 | Average Score: 6.0 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2590 | Average Score: 7.6 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2600 | Average Score: 6.4 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2610 | Average Score: 7.1 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2620 | Average Score: 4.2 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2630 | Average Score: 7.1 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2640 | Average Score: 5.9 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2650 | Average Score: 4.8 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2660 | Average Score: 6.0 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2670 | Average Score: 8.2 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2680 | Average Score: 7.0 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2690 | Average Score: 4.7 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2700 | Average Score: 10.3 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2710 | Average Score: 13.3 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2720 | Average Score: 6.7 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2730 | Average Score: 8.2 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2740 | Average Score: 6.4 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2750 | Average Score: 11.9 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2760 | Average Score: 13.4 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2770 | Average Score: 6.1 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2780 | Average Score: 5.2 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2790 | Average Score: 5.4 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2800 | Average Score: 11.1 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2810 | Average Score: 9.6 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2820 | Average Score: 8.9 | Best: 35 | Epsilon: 0.010\n",
      "Episode: 2830 | Average Score: 9.0 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2840 | Average Score: 6.0 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2850 | Average Score: 8.2 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2860 | Average Score: 13.3 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2870 | Average Score: 11.8 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2880 | Average Score: 13.3 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2890 | Average Score: 6.3 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2900 | Average Score: 5.9 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2910 | Average Score: 9.6 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2920 | Average Score: 7.1 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2930 | Average Score: 3.8 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2940 | Average Score: 5.2 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2950 | Average Score: 5.6 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2960 | Average Score: 4.5 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2970 | Average Score: 6.3 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2980 | Average Score: 5.4 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 2990 | Average Score: 6.8 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 3000 | Average Score: 7.6 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 3010 | Average Score: 9.2 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 3020 | Average Score: 10.8 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 3030 | Average Score: 3.1 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 3040 | Average Score: 5.1 | Best: 38 | Epsilon: 0.010\n",
      "Episode: 3050 | Average Score: 9.1 | Best: 38 | Epsilon: 0.010\n"
     ]
    }
   ],
   "source": [
    "episode_rewards_history = []\n",
    "episode_scores_history = []\n",
    "best_score_achieved = 0\n",
    "epsilon_greedy_value = EPS_START\n",
    "total_training_steps = 0\n",
    "try:\n",
    "    for episode in range(1, EPISODES + 1):\n",
    "        obs, _ = env.reset()\n",
    "        frame = preprocess(env.render())\n",
    "        state = stacker.reset(frame).to(DEVICE)\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            if random.random() < epsilon_greedy_value:\n",
    "                action = env.action_space.sample()  # Explore\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    state_input = state.unsqueeze(0).to(DEVICE)\n",
    "                    q_values = policy_net(state_input)\n",
    "                    action = q_values.argmax(1).item()  # Exploit\n",
    "\n",
    "            _, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            episode_reward += reward\n",
    "            next_frame = preprocess(env.render())\n",
    "            next_state = stacker.step(next_frame).to(DEVICE)\n",
    "            # Store transition\n",
    "            replay_buffer.push(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_training_steps += 1\n",
    "            # Training step\n",
    "            if len(replay_buffer) >= BATCH_SIZE:\n",
    "                s, a, r, ns, d = replay_buffer.sample(BATCH_SIZE)\n",
    "                s, a, r, ns, d = (\n",
    "                    s.to(DEVICE),\n",
    "                    a.to(DEVICE),\n",
    "                    r.to(DEVICE),\n",
    "                    ns.to(DEVICE),\n",
    "                    d.to(DEVICE),\n",
    "                )\n",
    "                q = policy_net(s).gather(1, a.unsqueeze(1)).squeeze(1).to(DEVICE)\n",
    "                with torch.no_grad():\n",
    "                    next_q = target_net(ns).max(1)[0]\n",
    "                    target = r + GAMMA * next_q * (1 - d)\n",
    "                loss = nn.functional.smooth_l1_loss(q, target)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # Update target network\n",
    "            if total_training_steps % TARGET_UPDATE == 0:\n",
    "                target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        episode_score = info.get(\"score\", 0)\n",
    "        if episode_score >= best_score_achieved:\n",
    "            best_score_achieved = episode_score\n",
    "            torch.save(policy_net.state_dict(), os.path.join(exp_path, \"best_model_score.pth\"))\n",
    "\n",
    "        episode_scores_history.append(info.get(\"score\", 0))\n",
    "        episode_rewards_history.append(episode_reward)\n",
    "        epsilon_greedy_value = max(EPS_END, epsilon_greedy_value * EPS_DECAY_RATE)\n",
    "        if episode % 10 == 0:\n",
    "            print(\n",
    "                f\"Episode: {episode} | \"\n",
    "                f\"Average Score: {np.mean(episode_scores_history[-10:])} | \"\n",
    "                f\"Best: {best_score_achieved} | \"\n",
    "                f\"Epsilon: {epsilon_greedy_value:.3f}\"\n",
    "            )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted by user.\")\n",
    "\n",
    "torch.save(policy_net.state_dict(),os.path.join(exp_path, \"final_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0273ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m figure, (reward_axis, score_axis) = \u001b[43mplot\u001b[49m.subplots(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, figsize=(\u001b[32m10\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m      3\u001b[39m reward_axis.plot(\n\u001b[32m      4\u001b[39m     episode_rewards_history,\n\u001b[32m      5\u001b[39m     color=\u001b[33m\"\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     alpha=\u001b[32m0.6\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m reward_axis.set_title(\u001b[33m\"\u001b[39m\u001b[33mReward per episode\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plot' is not defined"
     ]
    }
   ],
   "source": [
    "figure, (reward_axis, score_axis) = plot.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "reward_axis.plot(\n",
    "    episode_rewards_history,\n",
    "    color=\"blue\",\n",
    "    alpha=0.6\n",
    ")\n",
    "reward_axis.set_title(\"Reward per episode\")\n",
    "if len(episode_rewards_history) >= 100:\n",
    "    ma100 = np.convolve(episode_rewards_history, np.ones(100)/100, mode='valid')\n",
    "    reward_axis.plot(range(99, len(episode_rewards_history)), ma100, color=\"red\")\n",
    "score_axis.plot(\n",
    "    episode_scores_history,\n",
    "    color=\"green\",\n",
    "    alpha=0.6\n",
    ")\n",
    "if len(episode_scores_history) >= 100:\n",
    "    ma100 = np.convolve(episode_scores_history, np.ones(100)/100, mode='valid')\n",
    "    score_axis.plot(range(99, len(episode_scores_history)), ma100, color=\"green\", label=\"MA(100)\")\n",
    "score_axis.set_title(\"Score per episode\")\n",
    "\n",
    "plot.tight_layout()\n",
    "plot.savefig(os.path.join(exp_path, \"training_graph.png\"))\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f62e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished. Score: 56\n",
      "Episode 2 finished. Score: 74\n",
      "Episode 3 finished. Score: 72\n",
      "Episode 4 finished. Score: 5\n",
      "Episode 5 finished. Score: 323\n",
      "Episode 6 finished. Score: 164\n",
      "Episode 7 finished. Score: 25\n",
      "Episode 8 finished. Score: 1\n",
      "Episode 9 finished. Score: 47\n",
      "Episode 10 finished. Score: 299\n"
     ]
    }
   ],
   "source": [
    "model = FlappyCNN(num_actions).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"checkpoints\\\\best_flappy_pixels.pth\", map_location=DEVICE))\n",
    "model.eval()\n",
    "try:\n",
    "    for episode in range(10):\n",
    "        obs, _ = env.reset()\n",
    "        frame = env.render()\n",
    "        state = stacker.reset(preprocess(frame)).to(DEVICE)\n",
    "        done = False\n",
    "        while not done:\n",
    "            state_tensor = state.unsqueeze(0).to(DEVICE)\n",
    "            show_screen=cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imshow(\"Flappy Bird\", show_screen)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            with torch.no_grad():\n",
    "                action = model(state_tensor).argmax().item()\n",
    "\n",
    "            _, reward, term, trunc, info = env.step(action)\n",
    "            frame = env.render()\n",
    "            next_frame = preprocess(frame)\n",
    "            state = stacker.step(next_frame).to(DEVICE)\n",
    "            total_reward=info.get(\"score\",0)\n",
    "            if term or trunc:\n",
    "                print(f\"Episode {episode+1} finished. Score: {total_reward}\")\n",
    "                break\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Evaluation interrupted by user.\")\n",
    "env.close()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
